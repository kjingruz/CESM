# -*- coding: utf-8 -*-
"""Axial_MRI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fo6F94xfrPl7opTiBQs7Hg8u9wyPkwCo
"""

!nvidia-smi

!pip install roboflow

from roboflow import Roboflow
rf = Roboflow(api_key="92jyh8UFL7X56QYAPtge")
project = rf.workspace("roboflow-100").project("axial-mri")
version = project.version(1)
dataset = version.download("coco")

!ls

!pip install 'git+https://github.com/facebookresearch/detectron2.git'

import os
import json
import cv2
import random
import numpy as np
import torch
from google.colab.patches import cv2_imshow
from detectron2 import model_zoo
from detectron2.config import get_cfg
from detectron2.engine import DefaultTrainer, DefaultPredictor
from detectron2.data.datasets import register_coco_instances
from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader
from detectron2.utils.visualizer import Visualizer, ColorMode
from detectron2.evaluation import COCOEvaluator, inference_on_dataset

data_dir = "./axial-MRI-1"
train_json = os.path.join(data_dir, "train", "_annotations.coco.json")
val_json = os.path.join(data_dir, "valid", "_annotations.coco.json")
train_img_dir = os.path.join(data_dir, "train")
val_img_dir = os.path.join(data_dir, "valid")

# Register the datasets
register_coco_instances("mri_train", {}, train_json, train_img_dir)
register_coco_instances("mri_val", {}, val_json, val_img_dir)

mri_metadata = MetadataCatalog.get("mri_train")
dataset_dicts = DatasetCatalog.get("mri_train")
print("Number of training images:", len(dataset_dicts))

for d in random.sample(dataset_dicts, 3):
    img = cv2.imread(d["file_name"])
    visualizer = Visualizer(img[:, :, ::-1], metadata=mri_metadata, scale=0.5, instance_mode=ColorMode.IMAGE)
    vis = visualizer.draw_dataset_dict(d)
    cv2_imshow(vis.get_image()[:, :, ::-1])

cfg = get_cfg()
cfg.merge_from_file(model_zoo.get_config_file("COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml"))
cfg.DATASETS.TRAIN = ("mri_train",)
cfg.DATASETS.TEST = ("mri_val",)
cfg.DATALOADER.NUM_WORKERS = 2

# Pretrained weights from COCO
cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url("COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml")

cfg.SOLVER.IMS_PER_BATCH = 3
cfg.SOLVER.BASE_LR = 0.00025  # may adjust
cfg.SOLVER.MAX_ITER = 5000    # may adjust depending on dataset size
cfg.SOLVER.STEPS = []         # no LR step downs by default

cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512  # default 512, can adjust
cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3  # we have "negative" and "positive"

cfg.OUTPUT_DIR = "./output_mri"
os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)

trainer = DefaultTrainer(cfg)
trainer.resume_or_load(resume=False)
trainer.train()

cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, "model_final.pth")
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set a threshold for inference
predictor = DefaultPredictor(cfg)

evaluator = COCOEvaluator("mri_val", cfg, False, output_dir=cfg.OUTPUT_DIR)
val_loader = build_detection_test_loader(cfg, "mri_val")
print(inference_on_dataset(predictor.model, val_loader, evaluator))

dataset_dicts_val = DatasetCatalog.get("mri_val")

for d in random.sample(dataset_dicts_val, 3):
    im = cv2.imread(d["file_name"])
    outputs = predictor(im)
    v = Visualizer(im[:, :, ::-1],
                   metadata=mri_metadata,
                   scale=0.8,
                   instance_mode=ColorMode.IMAGE_BW)
    out = v.draw_instance_predictions(outputs["instances"].to("cpu"))
    cv2_imshow(out.get_image()[:, :, ::-1])

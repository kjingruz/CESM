# -*- coding: utf-8 -*-
"""PCB2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-GAyxyrzVPCre0MbZ116rW7nUFNqy8dF
"""

!nvidia-smi

!pip install roboflow

from roboflow import Roboflow
rf = Roboflow(api_key="92jyh8UFL7X56QYAPtge")
project = rf.workspace("rf-projects").project("pcb-holes")
version = project.version(3)
dataset = version.download("coco")

!pip install 'git+https://github.com/facebookresearch/detectron2.git'

import os
import json
import cv2
import random
import numpy as np
import torch
from google.colab.patches import cv2_imshow
from detectron2 import model_zoo
from detectron2.config import get_cfg
from detectron2.engine import DefaultTrainer, DefaultPredictor
from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader
from detectron2.data.datasets import register_coco_instances
from detectron2.utils.visualizer import Visualizer, ColorMode
from detectron2.evaluation import COCOEvaluator, inference_on_dataset

# Set the dataset paths
data_dir = "./PCB-Holes-3"
train_json = os.path.join(data_dir, "train/_annotations.coco.json")
val_json = os.path.join(data_dir, "valid/_annotations.coco.json")
train_img_dir = os.path.join(data_dir, "train")
val_img_dir = os.path.join(data_dir, "valid")

# Register datasets
register_coco_instances("pcb_train", {}, train_json, train_img_dir)
register_coco_instances("pcb_val", {}, val_json, val_img_dir)

pcb_metadata = MetadataCatalog.get("pcb_train")
dataset_dicts = DatasetCatalog.get("pcb_train")
print("Number of training images:", len(dataset_dicts))

for d in random.sample(dataset_dicts, 3):
    img = cv2.imread(d["file_name"])
    visualizer = Visualizer(img[:, :, ::-1], metadata=pcb_metadata, scale=0.5, instance_mode=ColorMode.IMAGE)
    vis = visualizer.draw_dataset_dict(d)
    cv2_imshow(vis.get_image()[:, :, ::-1])

cfg = get_cfg()
cfg.merge_from_file(model_zoo.get_config_file("COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml"))
cfg.DATASETS.TRAIN = ("pcb_train",)
cfg.DATASETS.TEST = ("pcb_val",)
cfg.DATALOADER.NUM_WORKERS = 2

# Use a pretrained COCO model as a starting point
cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url("COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml")

cfg.SOLVER.IMS_PER_BATCH = 2
cfg.SOLVER.BASE_LR = 0.00025  # Might adjust based on dataset
cfg.SOLVER.MAX_ITER = 3000    # Adjust based on dataset size
cfg.SOLVER.STEPS = []         # No LR step down
cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128  # Default: 512, might try smaller
cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2  # Set to number of classes in your PCB dataset

cfg.OUTPUT_DIR = "./output_pcb_holes"
os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)

trainer = DefaultTrainer(cfg)
trainer.resume_or_load(resume=False)
trainer.train()

# Load the trained weights
cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, "model_final.pth")
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set a custom testing threshold
predictor = DefaultPredictor(cfg)

evaluator = COCOEvaluator("pcb_val", cfg, False, output_dir=cfg.OUTPUT_DIR)
val_loader = build_detection_test_loader(cfg, "pcb_val")
inference_on_dataset(predictor.model, val_loader, evaluator)

dataset_dicts_val = DatasetCatalog.get("pcb_val")
for d in random.sample(dataset_dicts_val, 3):
    im = cv2.imread(d["file_name"])
    outputs = predictor(im)
    v = Visualizer(im[:, :, ::-1],
                   metadata=pcb_metadata,
                   scale=0.8,
                   instance_mode=ColorMode.IMAGE_BW)
    out = v.draw_instance_predictions(outputs["instances"].to("cpu"))
    cv2_imshow(out.get_image()[:, :, ::-1])